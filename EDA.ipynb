{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import albumentations\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    use_amp = False\n",
    "    debug = False\n",
    "    train_df_fp = \"data/train_folds.csv\"\n",
    "    test_df_fp = \"data/sample_submission.csv\"\n",
    "    num_workers = 8\n",
    "    model_name = \"resnet200d_320\"\n",
    "    image_size = 512\n",
    "    batch_size = 8\n",
    "    seed = 1710\n",
    "    target_size = 11\n",
    "    target_cols = [\n",
    "        \"ETT - Abnormal\",\n",
    "        \"ETT - Borderline\",\n",
    "        \"ETT - Normal\",\n",
    "        \"NGT - Abnormal\",\n",
    "        \"NGT - Borderline\",\n",
    "        \"NGT - Incompletely Imaged\",\n",
    "        \"NGT - Normal\",\n",
    "        \"CVC - Abnormal\",\n",
    "        \"CVC - Borderline\",\n",
    "        \"CVC - Normal\",\n",
    "        \"Swan Ganz Catheter Present\",\n",
    "    ]\n",
    "    fold = 0\n",
    "    output_dir = os.path.join(\"outputs\", \"checkpoints\", model_name)\n",
    "    submission_dir = os.path.join(\"outputs\", \"results\", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train_folds.csv\")\n",
    "test_df = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir = \"data/train\"\n",
    "test_img_dir = \"data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1710):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.bench_mark = True  # for faster training but not deterministic\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(Config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RANZCRDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        img_dir,\n",
    "        mode,\n",
    "        image_size=Config.image_size,\n",
    "        target_cols=Config.target_cols,\n",
    "    ):\n",
    "\n",
    "        self.df = self._get_df(df.copy(), img_dir)\n",
    "        self.labels = self.df[target_cols].values\n",
    "        self.mode = mode\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self._setup_transform()\n",
    "        if mode == \"train\":\n",
    "            self.transform = self.transform_train\n",
    "        elif mode == \"val\":\n",
    "            self.transform = self.transform_val\n",
    "        elif mode == \"test\":\n",
    "            self.transform = self.transform_test\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid mode {mode}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.df.iloc[idx]\n",
    "        img = cv2.imread(data[\"file_path\"])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transform(image=img)[\"image\"]\n",
    "        img = img.astype(np.float32)\n",
    "        img = img.transpose(2, 0, 1)\n",
    "        label = torch.tensor(self.labels[idx]).float()\n",
    "        if self.mode == \"test\":\n",
    "            return torch.tensor(img).float()\n",
    "        return torch.tensor(img).float(), label\n",
    "\n",
    "    def _setup_transform(self):\n",
    "        self.transform_train = albumentations.Compose(\n",
    "            [\n",
    "                albumentations.RandomResizedCrop(\n",
    "                    self.image_size, self.image_size, scale=(0.9, 1), p=1\n",
    "                ),\n",
    "                albumentations.HorizontalFlip(p=0.5),\n",
    "                albumentations.ShiftScaleRotate(p=0.5),\n",
    "                albumentations.HueSaturationValue(\n",
    "                    hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10, p=0.7\n",
    "                ),\n",
    "                albumentations.RandomBrightnessContrast(\n",
    "                    brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.7\n",
    "                ),\n",
    "                albumentations.CLAHE(clip_limit=(1, 4), p=0.5),\n",
    "                albumentations.OneOf(\n",
    "                    [\n",
    "                        albumentations.OpticalDistortion(distort_limit=1.0),\n",
    "                        albumentations.GridDistortion(num_steps=5, distort_limit=1.0),\n",
    "                        albumentations.ElasticTransform(alpha=3),\n",
    "                    ],\n",
    "                    p=0.2,\n",
    "                ),\n",
    "                albumentations.OneOf(\n",
    "                    [\n",
    "                        albumentations.GaussNoise(var_limit=[10, 50]),\n",
    "                        albumentations.GaussianBlur(),\n",
    "                        albumentations.MotionBlur(),\n",
    "                        albumentations.MedianBlur(),\n",
    "                    ],\n",
    "                    p=0.2,\n",
    "                ),\n",
    "                albumentations.Resize(self.image_size, self.image_size),\n",
    "                albumentations.OneOf(\n",
    "                    [\n",
    "                        albumentations.JpegCompression(),\n",
    "                        albumentations.Downscale(scale_min=0.1, scale_max=0.15),\n",
    "                    ],\n",
    "                    p=0.2,\n",
    "                ),\n",
    "                albumentations.IAAPiecewiseAffine(p=0.2),\n",
    "                albumentations.IAASharpen(p=0.2),\n",
    "                albumentations.Cutout(\n",
    "                    max_h_size=int(self.image_size * 0.1),\n",
    "                    max_w_size=int(self.image_size * 0.1),\n",
    "                    num_holes=5,\n",
    "                    p=0.5,\n",
    "                ),\n",
    "                albumentations.Normalize(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.transform_val = albumentations.Compose(\n",
    "            [\n",
    "                albumentations.Resize(self.image_size, self.image_size),\n",
    "                albumentations.Normalize(),\n",
    "            ]\n",
    "        )\n",
    "        self.transform_test = albumentations.Compose(\n",
    "            [\n",
    "                albumentations.Resize(self.image_size, self.image_size),\n",
    "                albumentations.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def _get_df(self, df, img_dir):\n",
    "        df[\"file_path\"] = df[\"StudyInstanceUID\"].apply(\n",
    "            lambda id_: os.path.join(img_dir, id_ + \".jpg\")\n",
    "        )\n",
    "        df = df.reset_index(drop=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RANZCRDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_df,\n",
    "        test_df,\n",
    "        train_img_dir,\n",
    "        test_img_dir,\n",
    "        fold,\n",
    "        batch_size=Config.batch_size,\n",
    "        image_size=Config.image_size,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train_df = train_df.copy()\n",
    "        self.test_df = test_df.copy()\n",
    "\n",
    "        #         split train-val\n",
    "        self.val_df = self.train_df[self.train_df[\"fold\"] == fold]\n",
    "        self.train_df = self.train_df[self.train_df[\"fold\"] != fold]\n",
    "\n",
    "        self.train_img_dir = train_img_dir\n",
    "        self.test_img_dir = test_img_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "\n",
    "        #         debug:\n",
    "        self.train_df = self.train_df.iloc[:100]\n",
    "        self.val_df = self.val_df.iloc[:100]\n",
    "        self.test_df = self.test_df.iloc[:100]\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        self.RANZCR_train = RANZCRDataset(\n",
    "            df=self.train_df,\n",
    "            img_dir=self.train_img_dir,\n",
    "            mode=\"train\",\n",
    "            image_size=self.image_size,\n",
    "        )\n",
    "        self.RANZCR_val = RANZCRDataset(\n",
    "            df=self.val_df,\n",
    "            img_dir=self.train_img_dir,\n",
    "            mode=\"val\",\n",
    "            image_size=self.image_size,\n",
    "        )\n",
    "        self.RANZCR_test = RANZCRDataset(\n",
    "            df=self.test_df,\n",
    "            img_dir=self.test_img_dir,\n",
    "            mode=\"test\",\n",
    "            image_size=self.image_size,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.RANZCR_train,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=Config.num_workers,\n",
    "            drop_last=True,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.RANZCR_val,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=Config.num_workers,\n",
    "            drop_last=False,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.RANZCR_test,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=Config.num_workers,\n",
    "            drop_last=False,\n",
    "            shuffle=False,\n",
    "            pin_memory=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = RANZCRDataModule(\n",
    "#     train_df=train_df,\n",
    "#     test_df=test_df,\n",
    "#     train_img_dir=train_img_dir,\n",
    "#     test_img_dir=test_img_dir,\n",
    "#     fold=0,\n",
    "# )\n",
    "# x.setup()\n",
    "# x.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F.binary_cross_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RANZCRModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name=Config.model_name,\n",
    "        output_dim=Config.target_size,\n",
    "        pretrained=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        n_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.backbone.global_pool = nn.Identity()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(n_features, output_dim)\n",
    "\n",
    "    def binary_loss(self, logits, labels):\n",
    "        return F.binary_cross_entropy_with_logits(logits, labels)\n",
    "\n",
    "    def macro_auc(self, labels, pred):\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        aucs = []\n",
    "        for i, col in enumerate(Config.target_cols):\n",
    "            fpr, tpr, threshold = roc_curve(labels[:, i], pred[:, i])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            aucs.append(roc_auc)\n",
    "\n",
    "            plt.plot(fpr, tpr, label=f\"Field {col} (AUC = {roc_auc:.4f})\")\n",
    "\n",
    "        mean_auc = np.mean(aucs)\n",
    "        std_auc = np.std(aucs)\n",
    "\n",
    "        ax.plot([0, 1], [0, 1], label=\"Luck\", linestyle=\"--\", color=\"r\")\n",
    "        ax.plot(\n",
    "            mean_auc, label=f\"Average AUC score: {mean_auc:.4f} $\\pm$ {std_auc:.4f}\"\n",
    "        )\n",
    "        ax.legend(loc=\"lower right\")\n",
    "        ax.set(\n",
    "            xlim=[-0.1, 1.1],\n",
    "            ylim=[-0.1, 1.1],\n",
    "            title=f\"Average AUC over {Config.target_size} fields\",\n",
    "        )\n",
    "        plt.show()\n",
    "        return mean_auc\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        features = self.backbone(x)\n",
    "        pooled_features = self.pooling(features).view(bs, -1)\n",
    "        output = self.fc(pooled_features)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "\n",
    "        x, y = train_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.binary_loss(logits, y).unsqueeze(0)\n",
    "        #         self.log(\"train_loss\", loss)\n",
    "        #         auc = self.macro_auc(logits, y)\n",
    "        tb_log = {\n",
    "            \"train_loss\": loss,\n",
    "            #                   \"train_auc\": auc\n",
    "        }\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            #                 \"train_auc\": auc,\n",
    "            \"log\": tb_log,\n",
    "        }\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.binary_loss(logits, y).unsqueeze(0)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        #         self.log('val_loss', loss)\n",
    "        #         already call torch.no_grad() so we had not to call the detach()\n",
    "        auc = self.macro_auc(logits.cpu().numpy(), y.cpu().numpy())\n",
    "        tb_log = {\"val_loss\": loss, \"val_auc\": auc}\n",
    "        return {\"val_loss\": loss, \"val_auc\": auc, \"log\": tb_log}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.cat([out[\"val_loss\"] for out in outputs], dim=0).mean()\n",
    "        avg_auc = torch.cat([out[\"val_auc\"] for out in outputs], dim=0).mean()\n",
    "        print(f\"EPOCH: {self.current_epoch} AUC:{auc:.4f}\")\n",
    "        tensorboard_logs = {\"val_loss\": avg_loss, \"val_auc\": avg_auc}\n",
    "        return {\"avg_val_loss\": avg_loss, \"val_auc\": avg_auc, \"log\": tensorboard_logs}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        logits = self.forward(batch)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        return {\"probs\": probs}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        y_hat = torch.cat([x[\"y_hat\"] for x in outputs])\n",
    "        df_test[\"target\"] = y_hat.tolist()\n",
    "\n",
    "        os.makedirs(Config.output_dir, exists_ok=True)\n",
    "        os.makedirs(Config.submission_dir, exists_ok=True)\n",
    "        N = len(os.listdir(Config.output_dir))\n",
    "        df_test.target.to_csv(os.path.join(Config.submission_dir, f\"submission{N}.csv\"))\n",
    "        return {\"tta\": N}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = RANZCRModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    \"{epoch:02d}_{val_auc:.4f}\",\n",
    "    monitor=\"val_auc\",\n",
    "    mode=\"max\",\n",
    "    #     save_top_k=1,\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    precision=16,\n",
    "    max_epochs=30,\n",
    "    num_sanity_val_steps=1 if Config.debug else 0,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    #     val_check_interval=0.25, # check validation 4 times per epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RANZCRModel()\n",
    "data_module = RANZCRDataModule(\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    train_img_dir=train_img_dir,\n",
    "    test_img_dir=test_img_dir,\n",
    "    fold=0,\n",
    ")\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
