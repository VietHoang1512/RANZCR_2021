{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\\n\\nimport os\\nimport glob\\nimport pandas as pd\\nimport numpy as np\\nimport random\\n\\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\\nimport seaborn as sns\\nfrom matplotlib import pyplot as plt\\n\\nimport cv2\\n\\nimport torch\\nimport torch.nn as nn\\nimport torch.nn.functional as F\\nfrom torch.utils.data import DataLoader, Dataset\\n\\nimport torchvision\\n\\nimport pytorch_lightning as pl\\n\\nimport albumentations\\nfrom albumentations.pytorch import ToTensorV2\\n\\nimport timm\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\\n\\nimport os\\nimport glob\\nimport pandas as pd\\nimport numpy as np\\nimport random\\n\\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\\nimport seaborn as sns\\nfrom matplotlib import pyplot as plt\\n\\nimport cv2\\n\\nimport torch\\nimport torch.nn as nn\\nimport torch.nn.functional as F\\nfrom torch.utils.data import DataLoader, Dataset\\n\\nimport torchvision\\n\\nimport pytorch_lightning as pl\\n\\nimport albumentations\\nfrom albumentations.pytorch import ToTensorV2\\n\\nimport timm\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import albumentations\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"class Config:\\n    use_amp = False\\n    debug = False\\n    train_df_fp = \\\"data/train_folds.csv\\\"\\n    test_df_fp = \\\"data/sample_submission.csv\\\"\\n    num_workers = 8\\n    model_name = \\\"resnet200d_320\\\"\\n    image_size = 512\\n    batch_size = 8\\n    seed = 1710\\n    target_size = 11\\n    target_cols = [\\n        \\\"ETT - Abnormal\\\",\\n        \\\"ETT - Borderline\\\",\\n        \\\"ETT - Normal\\\",\\n        \\\"NGT - Abnormal\\\",\\n        \\\"NGT - Borderline\\\",\\n        \\\"NGT - Incompletely Imaged\\\",\\n        \\\"NGT - Normal\\\",\\n        \\\"CVC - Abnormal\\\",\\n        \\\"CVC - Borderline\\\",\\n        \\\"CVC - Normal\\\",\\n        \\\"Swan Ganz Catheter Present\\\",\\n    ]\\n    fold = 0\\n    output_dir = os.path.join(\\\"outputs\\\", \\\"checkpoints\\\", model_name)\\n    submission_dir = os.path.join(\\\"outputs\\\", \\\"results\\\", model_name)\";\n",
       "                var nbb_formatted_code = \"class Config:\\n    use_amp = False\\n    debug = False\\n    train_df_fp = \\\"data/train_folds.csv\\\"\\n    test_df_fp = \\\"data/sample_submission.csv\\\"\\n    num_workers = 8\\n    model_name = \\\"resnet200d_320\\\"\\n    image_size = 512\\n    batch_size = 8\\n    seed = 1710\\n    target_size = 11\\n    target_cols = [\\n        \\\"ETT - Abnormal\\\",\\n        \\\"ETT - Borderline\\\",\\n        \\\"ETT - Normal\\\",\\n        \\\"NGT - Abnormal\\\",\\n        \\\"NGT - Borderline\\\",\\n        \\\"NGT - Incompletely Imaged\\\",\\n        \\\"NGT - Normal\\\",\\n        \\\"CVC - Abnormal\\\",\\n        \\\"CVC - Borderline\\\",\\n        \\\"CVC - Normal\\\",\\n        \\\"Swan Ganz Catheter Present\\\",\\n    ]\\n    fold = 0\\n    output_dir = os.path.join(\\\"outputs\\\", \\\"checkpoints\\\", model_name)\\n    submission_dir = os.path.join(\\\"outputs\\\", \\\"results\\\", model_name)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Config:\n",
    "    use_amp = False\n",
    "    debug = False\n",
    "    train_df_fp = \"data/train_folds.csv\"\n",
    "    test_df_fp = \"data/sample_submission.csv\"\n",
    "    num_workers = 8\n",
    "    model_name = \"resnet200d_320\"\n",
    "    image_size = 512\n",
    "    batch_size = 8\n",
    "    seed = 1710\n",
    "    target_size = 11\n",
    "    target_cols = [\n",
    "        \"ETT - Abnormal\",\n",
    "        \"ETT - Borderline\",\n",
    "        \"ETT - Normal\",\n",
    "        \"NGT - Abnormal\",\n",
    "        \"NGT - Borderline\",\n",
    "        \"NGT - Incompletely Imaged\",\n",
    "        \"NGT - Normal\",\n",
    "        \"CVC - Abnormal\",\n",
    "        \"CVC - Borderline\",\n",
    "        \"CVC - Normal\",\n",
    "        \"Swan Ganz Catheter Present\",\n",
    "    ]\n",
    "    fold = 0\n",
    "    output_dir = os.path.join(\"outputs\", \"checkpoints\", model_name)\n",
    "    submission_dir = os.path.join(\"outputs\", \"results\", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"os.environ[\\\"CUDA_DEVICE_ORDER\\\"] = \\\"PCI_BUS_ID\\\"  # see issue #152\\nos.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"1\\\"\";\n",
       "                var nbb_formatted_code = \"os.environ[\\\"CUDA_DEVICE_ORDER\\\"] = \\\"PCI_BUS_ID\\\"  # see issue #152\\nos.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"1\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test',\n",
       " 'train',\n",
       " 'sample_submission.csv',\n",
       " 'train.csv',\n",
       " 'train_tfrecords',\n",
       " 'train_folds.csv',\n",
       " 'test_tfrecords',\n",
       " 'train_annotations.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"os.listdir(\\\"data\\\")\";\n",
       "                var nbb_formatted_code = \"os.listdir(\\\"data\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.listdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"train_df = pd.read_csv(\\\"data/train_folds.csv\\\")\\ntest_df = pd.read_csv(\\\"data/sample_submission.csv\\\")\";\n",
       "                var nbb_formatted_code = \"train_df = pd.read_csv(\\\"data/train_folds.csv\\\")\\ntest_df = pd.read_csv(\\\"data/sample_submission.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"data/train_folds.csv\")\n",
    "test_df = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>ETT - Abnormal</th>\n",
       "      <th>ETT - Borderline</th>\n",
       "      <th>ETT - Normal</th>\n",
       "      <th>NGT - Abnormal</th>\n",
       "      <th>NGT - Borderline</th>\n",
       "      <th>NGT - Incompletely Imaged</th>\n",
       "      <th>NGT - Normal</th>\n",
       "      <th>CVC - Abnormal</th>\n",
       "      <th>CVC - Borderline</th>\n",
       "      <th>CVC - Normal</th>\n",
       "      <th>Swan Ganz Catheter Present</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.26697628953273228189...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ec89415d1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.46302891597398758759...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>bf4c6da3c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.23819260719748494858...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3fc1c97e5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.68286643202323212801...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c31019814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.10050203009225938259...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>207685cd1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    StudyInstanceUID  ETT - Abnormal  \\\n",
       "0  1.2.826.0.1.3680043.8.498.26697628953273228189...               0   \n",
       "1  1.2.826.0.1.3680043.8.498.46302891597398758759...               0   \n",
       "2  1.2.826.0.1.3680043.8.498.23819260719748494858...               0   \n",
       "3  1.2.826.0.1.3680043.8.498.68286643202323212801...               0   \n",
       "4  1.2.826.0.1.3680043.8.498.10050203009225938259...               0   \n",
       "\n",
       "   ETT - Borderline  ETT - Normal  NGT - Abnormal  NGT - Borderline  \\\n",
       "0                 0             0               0                 0   \n",
       "1                 0             1               0                 0   \n",
       "2                 0             0               0                 0   \n",
       "3                 0             0               0                 0   \n",
       "4                 0             0               0                 0   \n",
       "\n",
       "   NGT - Incompletely Imaged  NGT - Normal  CVC - Abnormal  CVC - Borderline  \\\n",
       "0                          0             1               0                 0   \n",
       "1                          1             0               0                 0   \n",
       "2                          0             0               0                 1   \n",
       "3                          0             0               1                 0   \n",
       "4                          0             0               0                 0   \n",
       "\n",
       "   CVC - Normal  Swan Ganz Catheter Present  PatientID  fold  \n",
       "0             0                           0  ec89415d1     3  \n",
       "1             1                           0  bf4c6da3c     3  \n",
       "2             0                           0  3fc1c97e5     3  \n",
       "3             0                           0  c31019814     0  \n",
       "4             1                           0  207685cd1     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>ETT - Abnormal</th>\n",
       "      <th>ETT - Borderline</th>\n",
       "      <th>ETT - Normal</th>\n",
       "      <th>NGT - Abnormal</th>\n",
       "      <th>NGT - Borderline</th>\n",
       "      <th>NGT - Incompletely Imaged</th>\n",
       "      <th>NGT - Normal</th>\n",
       "      <th>CVC - Abnormal</th>\n",
       "      <th>CVC - Borderline</th>\n",
       "      <th>CVC - Normal</th>\n",
       "      <th>Swan Ganz Catheter Present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.46923145579096002617...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.84006870182611080091...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.12219033294413119947...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.84994474380235968109...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.35798987793805669662...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    StudyInstanceUID  ETT - Abnormal  \\\n",
       "0  1.2.826.0.1.3680043.8.498.46923145579096002617...               0   \n",
       "1  1.2.826.0.1.3680043.8.498.84006870182611080091...               0   \n",
       "2  1.2.826.0.1.3680043.8.498.12219033294413119947...               0   \n",
       "3  1.2.826.0.1.3680043.8.498.84994474380235968109...               0   \n",
       "4  1.2.826.0.1.3680043.8.498.35798987793805669662...               0   \n",
       "\n",
       "   ETT - Borderline  ETT - Normal  NGT - Abnormal  NGT - Borderline  \\\n",
       "0                 0             0               0                 0   \n",
       "1                 0             0               0                 0   \n",
       "2                 0             0               0                 0   \n",
       "3                 0             0               0                 0   \n",
       "4                 0             0               0                 0   \n",
       "\n",
       "   NGT - Incompletely Imaged  NGT - Normal  CVC - Abnormal  CVC - Borderline  \\\n",
       "0                          0             0               0                 0   \n",
       "1                          0             0               0                 0   \n",
       "2                          0             0               0                 0   \n",
       "3                          0             0               0                 0   \n",
       "4                          0             0               0                 0   \n",
       "\n",
       "   CVC - Normal  Swan Ganz Catheter Present  \n",
       "0             0                           0  \n",
       "1             0                           0  \n",
       "2             0                           0  \n",
       "3             0                           0  \n",
       "4             0                           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"display(train_df.head())\\ndisplay(test_df.head())\";\n",
       "                var nbb_formatted_code = \"display(train_df.head())\\ndisplay(test_df.head())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"train_img_dir = \\\"data/train\\\"\\ntest_img_dir = \\\"data/test\\\"\";\n",
       "                var nbb_formatted_code = \"train_img_dir = \\\"data/train\\\"\\ntest_img_dir = \\\"data/test\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_img_dir = \"data/train\"\n",
    "test_img_dir = \"data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"def seed_everything(seed=1710):\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(seed)\\n    random.seed(seed)\\n    np.random.seed(seed)\\n    torch.manual_seed(seed)\\n    torch.cuda.manual_seed(seed)\\n    torch.backends.cudnn.bench_mark = True  # for faster training but not deterministic\\n    torch.backends.cudnn.deterministic = True\";\n",
       "                var nbb_formatted_code = \"def seed_everything(seed=1710):\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(seed)\\n    random.seed(seed)\\n    np.random.seed(seed)\\n    torch.manual_seed(seed)\\n    torch.cuda.manual_seed(seed)\\n    torch.backends.cudnn.bench_mark = True  # for faster training but not deterministic\\n    torch.backends.cudnn.deterministic = True\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def seed_everything(seed=1710):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.bench_mark = True  # for faster training but not deterministic\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"seed_everything(Config.seed)\";\n",
       "                var nbb_formatted_code = \"seed_everything(Config.seed)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed_everything(Config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class RANZCRDataset(Dataset):\\n    def __init__(\\n        self,\\n        df,\\n        img_dir,\\n        mode,\\n        image_size=Config.image_size,\\n        target_cols=Config.target_cols,\\n    ):\\n\\n        self.df = self._get_df(df.copy(), img_dir)\\n        self.labels = self.df[target_cols].values\\n        self.mode = mode\\n        self.image_size = image_size\\n\\n        self._setup_transform()\\n        if mode == \\\"train\\\":\\n            self.transform = self.transform_train\\n        elif mode == \\\"val\\\":\\n            self.transform = self.transform_val\\n        elif mode == \\\"test\\\":\\n            self.transform = self.transform_test\\n        else:\\n            raise ValueError(f\\\"Invalid mode {mode}\\\")\\n\\n    def __len__(self):\\n        return len(self.df)\\n\\n    def __getitem__(self, idx):\\n        data = self.df.iloc[idx]\\n        img = cv2.imread(data[\\\"file_path\\\"])\\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\\n        img = self.transform(image=img)[\\\"image\\\"]\\n        img = img.astype(np.float32)\\n        img = img.transpose(2, 0, 1)\\n        label = torch.tensor(self.labels[idx]).float()\\n        if self.mode == \\\"test\\\":\\n            return torch.tensor(img).float()\\n        return torch.tensor(img).float(), label\\n\\n    def _setup_transform(self):\\n        self.transform_train = albumentations.Compose(\\n            [\\n                albumentations.RandomResizedCrop(\\n                    self.image_size, self.image_size, scale=(0.9, 1), p=1\\n                ),\\n                albumentations.HorizontalFlip(p=0.5),\\n                albumentations.ShiftScaleRotate(p=0.5),\\n                albumentations.HueSaturationValue(\\n                    hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10, p=0.7\\n                ),\\n                albumentations.RandomBrightnessContrast(\\n                    brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.7\\n                ),\\n                albumentations.CLAHE(clip_limit=(1, 4), p=0.5),\\n                albumentations.OneOf(\\n                    [\\n                        albumentations.OpticalDistortion(distort_limit=1.0),\\n                        albumentations.GridDistortion(num_steps=5, distort_limit=1.0),\\n                        albumentations.ElasticTransform(alpha=3),\\n                    ],\\n                    p=0.2,\\n                ),\\n                albumentations.OneOf(\\n                    [\\n                        albumentations.GaussNoise(var_limit=[10, 50]),\\n                        albumentations.GaussianBlur(),\\n                        albumentations.MotionBlur(),\\n                        albumentations.MedianBlur(),\\n                    ],\\n                    p=0.2,\\n                ),\\n                albumentations.Resize(self.image_size, self.image_size),\\n                albumentations.OneOf(\\n                    [\\n                        albumentations.JpegCompression(),\\n                        albumentations.Downscale(scale_min=0.1, scale_max=0.15),\\n                    ],\\n                    p=0.2,\\n                ),\\n                albumentations.IAAPiecewiseAffine(p=0.2),\\n                albumentations.IAASharpen(p=0.2),\\n                albumentations.Cutout(\\n                    max_h_size=int(self.image_size * 0.1),\\n                    max_w_size=int(self.image_size * 0.1),\\n                    num_holes=5,\\n                    p=0.5,\\n                ),\\n                albumentations.Normalize(),\\n            ]\\n        )\\n\\n        self.transform_val = albumentations.Compose(\\n            [\\n                albumentations.Resize(self.image_size, self.image_size),\\n                albumentations.Normalize(),\\n            ]\\n        )\\n        self.transform_test = albumentations.Compose(\\n            [\\n                albumentations.Resize(self.image_size, self.image_size),\\n                albumentations.Normalize(\\n                    mean=[0.485, 0.456, 0.406],\\n                    std=[0.229, 0.224, 0.225],\\n                ),\\n                ToTensorV2(),\\n            ]\\n        )\\n\\n    def _get_df(self, df, img_dir):\\n        df[\\\"file_path\\\"] = df[\\\"StudyInstanceUID\\\"].apply(\\n            lambda id_: os.path.join(img_dir, id_ + \\\".jpg\\\")\\n        )\\n        df = df.reset_index(drop=True)\\n        return df\";\n",
       "                var nbb_formatted_code = \"class RANZCRDataset(Dataset):\\n    def __init__(\\n        self,\\n        df,\\n        img_dir,\\n        mode,\\n        image_size=Config.image_size,\\n        target_cols=Config.target_cols,\\n    ):\\n\\n        self.df = self._get_df(df.copy(), img_dir)\\n        self.labels = self.df[target_cols].values\\n        self.mode = mode\\n        self.image_size = image_size\\n\\n        self._setup_transform()\\n        if mode == \\\"train\\\":\\n            self.transform = self.transform_train\\n        elif mode == \\\"val\\\":\\n            self.transform = self.transform_val\\n        elif mode == \\\"test\\\":\\n            self.transform = self.transform_test\\n        else:\\n            raise ValueError(f\\\"Invalid mode {mode}\\\")\\n\\n    def __len__(self):\\n        return len(self.df)\\n\\n    def __getitem__(self, idx):\\n        data = self.df.iloc[idx]\\n        img = cv2.imread(data[\\\"file_path\\\"])\\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\\n        img = self.transform(image=img)[\\\"image\\\"]\\n        img = img.astype(np.float32)\\n        img = img.transpose(2, 0, 1)\\n        label = torch.tensor(self.labels[idx]).float()\\n        if self.mode == \\\"test\\\":\\n            return torch.tensor(img).float()\\n        return torch.tensor(img).float(), label\\n\\n    def _setup_transform(self):\\n        self.transform_train = albumentations.Compose(\\n            [\\n                albumentations.RandomResizedCrop(\\n                    self.image_size, self.image_size, scale=(0.9, 1), p=1\\n                ),\\n                albumentations.HorizontalFlip(p=0.5),\\n                albumentations.ShiftScaleRotate(p=0.5),\\n                albumentations.HueSaturationValue(\\n                    hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10, p=0.7\\n                ),\\n                albumentations.RandomBrightnessContrast(\\n                    brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.7\\n                ),\\n                albumentations.CLAHE(clip_limit=(1, 4), p=0.5),\\n                albumentations.OneOf(\\n                    [\\n                        albumentations.OpticalDistortion(distort_limit=1.0),\\n                        albumentations.GridDistortion(num_steps=5, distort_limit=1.0),\\n                        albumentations.ElasticTransform(alpha=3),\\n                    ],\\n                    p=0.2,\\n                ),\\n                albumentations.OneOf(\\n                    [\\n                        albumentations.GaussNoise(var_limit=[10, 50]),\\n                        albumentations.GaussianBlur(),\\n                        albumentations.MotionBlur(),\\n                        albumentations.MedianBlur(),\\n                    ],\\n                    p=0.2,\\n                ),\\n                albumentations.Resize(self.image_size, self.image_size),\\n                albumentations.OneOf(\\n                    [\\n                        albumentations.JpegCompression(),\\n                        albumentations.Downscale(scale_min=0.1, scale_max=0.15),\\n                    ],\\n                    p=0.2,\\n                ),\\n                albumentations.IAAPiecewiseAffine(p=0.2),\\n                albumentations.IAASharpen(p=0.2),\\n                albumentations.Cutout(\\n                    max_h_size=int(self.image_size * 0.1),\\n                    max_w_size=int(self.image_size * 0.1),\\n                    num_holes=5,\\n                    p=0.5,\\n                ),\\n                albumentations.Normalize(),\\n            ]\\n        )\\n\\n        self.transform_val = albumentations.Compose(\\n            [\\n                albumentations.Resize(self.image_size, self.image_size),\\n                albumentations.Normalize(),\\n            ]\\n        )\\n        self.transform_test = albumentations.Compose(\\n            [\\n                albumentations.Resize(self.image_size, self.image_size),\\n                albumentations.Normalize(\\n                    mean=[0.485, 0.456, 0.406],\\n                    std=[0.229, 0.224, 0.225],\\n                ),\\n                ToTensorV2(),\\n            ]\\n        )\\n\\n    def _get_df(self, df, img_dir):\\n        df[\\\"file_path\\\"] = df[\\\"StudyInstanceUID\\\"].apply(\\n            lambda id_: os.path.join(img_dir, id_ + \\\".jpg\\\")\\n        )\\n        df = df.reset_index(drop=True)\\n        return df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class RANZCRDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        img_dir,\n",
    "        mode,\n",
    "        image_size=Config.image_size,\n",
    "        target_cols=Config.target_cols,\n",
    "    ):\n",
    "\n",
    "        self.df = self._get_df(df.copy(), img_dir)\n",
    "        self.labels = self.df[target_cols].values\n",
    "        self.mode = mode\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self._setup_transform()\n",
    "        if mode == \"train\":\n",
    "            self.transform = self.transform_train\n",
    "        elif mode == \"val\":\n",
    "            self.transform = self.transform_val\n",
    "        elif mode == \"test\":\n",
    "            self.transform = self.transform_test\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid mode {mode}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.df.iloc[idx]\n",
    "        img = cv2.imread(data[\"file_path\"])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transform(image=img)[\"image\"]\n",
    "        img = img.astype(np.float32)\n",
    "        img = img.transpose(2, 0, 1)\n",
    "        label = torch.tensor(self.labels[idx]).float()\n",
    "        if self.mode == \"test\":\n",
    "            return torch.tensor(img).float()\n",
    "        return torch.tensor(img).float(), label\n",
    "\n",
    "    def _setup_transform(self):\n",
    "        self.transform_train = albumentations.Compose(\n",
    "            [\n",
    "                albumentations.RandomResizedCrop(\n",
    "                    self.image_size, self.image_size, scale=(0.9, 1), p=1\n",
    "                ),\n",
    "                albumentations.HorizontalFlip(p=0.5),\n",
    "                albumentations.ShiftScaleRotate(p=0.5),\n",
    "                albumentations.HueSaturationValue(\n",
    "                    hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10, p=0.7\n",
    "                ),\n",
    "                albumentations.RandomBrightnessContrast(\n",
    "                    brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.7\n",
    "                ),\n",
    "                albumentations.CLAHE(clip_limit=(1, 4), p=0.5),\n",
    "                albumentations.OneOf(\n",
    "                    [\n",
    "                        albumentations.OpticalDistortion(distort_limit=1.0),\n",
    "                        albumentations.GridDistortion(num_steps=5, distort_limit=1.0),\n",
    "                        albumentations.ElasticTransform(alpha=3),\n",
    "                    ],\n",
    "                    p=0.2,\n",
    "                ),\n",
    "                albumentations.OneOf(\n",
    "                    [\n",
    "                        albumentations.GaussNoise(var_limit=[10, 50]),\n",
    "                        albumentations.GaussianBlur(),\n",
    "                        albumentations.MotionBlur(),\n",
    "                        albumentations.MedianBlur(),\n",
    "                    ],\n",
    "                    p=0.2,\n",
    "                ),\n",
    "                albumentations.Resize(self.image_size, self.image_size),\n",
    "                albumentations.OneOf(\n",
    "                    [\n",
    "                        albumentations.JpegCompression(),\n",
    "                        albumentations.Downscale(scale_min=0.1, scale_max=0.15),\n",
    "                    ],\n",
    "                    p=0.2,\n",
    "                ),\n",
    "                albumentations.IAAPiecewiseAffine(p=0.2),\n",
    "                albumentations.IAASharpen(p=0.2),\n",
    "                albumentations.Cutout(\n",
    "                    max_h_size=int(self.image_size * 0.1),\n",
    "                    max_w_size=int(self.image_size * 0.1),\n",
    "                    num_holes=5,\n",
    "                    p=0.5,\n",
    "                ),\n",
    "                albumentations.Normalize(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.transform_val = albumentations.Compose(\n",
    "            [\n",
    "                albumentations.Resize(self.image_size, self.image_size),\n",
    "                albumentations.Normalize(),\n",
    "            ]\n",
    "        )\n",
    "        self.transform_test = albumentations.Compose(\n",
    "            [\n",
    "                albumentations.Resize(self.image_size, self.image_size),\n",
    "                albumentations.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def _get_df(self, df, img_dir):\n",
    "        df[\"file_path\"] = df[\"StudyInstanceUID\"].apply(\n",
    "            lambda id_: os.path.join(img_dir, id_ + \".jpg\")\n",
    "        )\n",
    "        df = df.reset_index(drop=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class RANZCRDataModule(pl.LightningDataModule):\\n    def __init__(\\n        self,\\n        train_df,\\n        test_df,\\n        train_img_dir,\\n        test_img_dir,\\n        fold,\\n        batch_size=Config.batch_size,\\n        image_size=Config.image_size,\\n    ):\\n        super().__init__()\\n        self.train_df = train_df.copy()\\n        self.test_df = test_df.copy()\\n\\n        #         split train-val\\n        self.val_df = self.train_df[self.train_df[\\\"fold\\\"] == fold]\\n        self.train_df = self.train_df[self.train_df[\\\"fold\\\"] != fold]\\n\\n        self.train_img_dir = train_img_dir\\n        self.test_img_dir = test_img_dir\\n        self.batch_size = batch_size\\n        self.image_size = image_size\\n\\n        #         debug:\\n        self.train_df = self.train_df.iloc[:100]\\n        self.val_df = self.val_df.iloc[:100]\\n        self.test_df = self.test_df.iloc[:100]\\n\\n    def setup(self, stage=None):\\n\\n        self.RANZCR_train = RANZCRDataset(\\n            df=self.train_df,\\n            img_dir=self.train_img_dir,\\n            mode=\\\"train\\\",\\n            image_size=self.image_size,\\n        )\\n        self.RANZCR_val = RANZCRDataset(\\n            df=self.val_df,\\n            img_dir=self.train_img_dir,\\n            mode=\\\"val\\\",\\n            image_size=self.image_size,\\n        )\\n        self.RANZCR_test = RANZCRDataset(\\n            df=self.test_df,\\n            img_dir=self.test_img_dir,\\n            mode=\\\"test\\\",\\n            image_size=self.image_size,\\n        )\\n\\n    def train_dataloader(self) -> DataLoader:\\n        return DataLoader(\\n            self.RANZCR_train,\\n            batch_size=self.batch_size,\\n            num_workers=Config.num_workers,\\n            drop_last=True,\\n            shuffle=True,\\n            pin_memory=True,\\n        )\\n\\n    def val_dataloader(self) -> DataLoader:\\n        return DataLoader(\\n            self.RANZCR_val,\\n            batch_size=self.batch_size,\\n            num_workers=Config.num_workers,\\n            drop_last=False,\\n            shuffle=False,\\n            pin_memory=True,\\n        )\\n\\n    def test_dataloader(self) -> DataLoader:\\n        return DataLoader(\\n            self.RANZCR_test,\\n            batch_size=self.batch_size,\\n            num_workers=Config.num_workers,\\n            drop_last=False,\\n            shuffle=False,\\n            pin_memory=False,\\n        )\";\n",
       "                var nbb_formatted_code = \"class RANZCRDataModule(pl.LightningDataModule):\\n    def __init__(\\n        self,\\n        train_df,\\n        test_df,\\n        train_img_dir,\\n        test_img_dir,\\n        fold,\\n        batch_size=Config.batch_size,\\n        image_size=Config.image_size,\\n    ):\\n        super().__init__()\\n        self.train_df = train_df.copy()\\n        self.test_df = test_df.copy()\\n\\n        #         split train-val\\n        self.val_df = self.train_df[self.train_df[\\\"fold\\\"] == fold]\\n        self.train_df = self.train_df[self.train_df[\\\"fold\\\"] != fold]\\n\\n        self.train_img_dir = train_img_dir\\n        self.test_img_dir = test_img_dir\\n        self.batch_size = batch_size\\n        self.image_size = image_size\\n\\n        #         debug:\\n        self.train_df = self.train_df.iloc[:100]\\n        self.val_df = self.val_df.iloc[:100]\\n        self.test_df = self.test_df.iloc[:100]\\n\\n    def setup(self, stage=None):\\n\\n        self.RANZCR_train = RANZCRDataset(\\n            df=self.train_df,\\n            img_dir=self.train_img_dir,\\n            mode=\\\"train\\\",\\n            image_size=self.image_size,\\n        )\\n        self.RANZCR_val = RANZCRDataset(\\n            df=self.val_df,\\n            img_dir=self.train_img_dir,\\n            mode=\\\"val\\\",\\n            image_size=self.image_size,\\n        )\\n        self.RANZCR_test = RANZCRDataset(\\n            df=self.test_df,\\n            img_dir=self.test_img_dir,\\n            mode=\\\"test\\\",\\n            image_size=self.image_size,\\n        )\\n\\n    def train_dataloader(self) -> DataLoader:\\n        return DataLoader(\\n            self.RANZCR_train,\\n            batch_size=self.batch_size,\\n            num_workers=Config.num_workers,\\n            drop_last=True,\\n            shuffle=True,\\n            pin_memory=True,\\n        )\\n\\n    def val_dataloader(self) -> DataLoader:\\n        return DataLoader(\\n            self.RANZCR_val,\\n            batch_size=self.batch_size,\\n            num_workers=Config.num_workers,\\n            drop_last=False,\\n            shuffle=False,\\n            pin_memory=True,\\n        )\\n\\n    def test_dataloader(self) -> DataLoader:\\n        return DataLoader(\\n            self.RANZCR_test,\\n            batch_size=self.batch_size,\\n            num_workers=Config.num_workers,\\n            drop_last=False,\\n            shuffle=False,\\n            pin_memory=False,\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class RANZCRDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_df,\n",
    "        test_df,\n",
    "        train_img_dir,\n",
    "        test_img_dir,\n",
    "        fold,\n",
    "        batch_size=Config.batch_size,\n",
    "        image_size=Config.image_size,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train_df = train_df.copy()\n",
    "        self.test_df = test_df.copy()\n",
    "\n",
    "        #         split train-val\n",
    "        self.val_df = self.train_df[self.train_df[\"fold\"] == fold]\n",
    "        self.train_df = self.train_df[self.train_df[\"fold\"] != fold]\n",
    "\n",
    "        self.train_img_dir = train_img_dir\n",
    "        self.test_img_dir = test_img_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "\n",
    "        #         debug:\n",
    "        self.train_df = self.train_df.iloc[:100]\n",
    "        self.val_df = self.val_df.iloc[:100]\n",
    "        self.test_df = self.test_df.iloc[:100]\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        self.RANZCR_train = RANZCRDataset(\n",
    "            df=self.train_df,\n",
    "            img_dir=self.train_img_dir,\n",
    "            mode=\"train\",\n",
    "            image_size=self.image_size,\n",
    "        )\n",
    "        self.RANZCR_val = RANZCRDataset(\n",
    "            df=self.val_df,\n",
    "            img_dir=self.train_img_dir,\n",
    "            mode=\"val\",\n",
    "            image_size=self.image_size,\n",
    "        )\n",
    "        self.RANZCR_test = RANZCRDataset(\n",
    "            df=self.test_df,\n",
    "            img_dir=self.test_img_dir,\n",
    "            mode=\"test\",\n",
    "            image_size=self.image_size,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.RANZCR_train,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=Config.num_workers,\n",
    "            drop_last=True,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.RANZCR_val,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=Config.num_workers,\n",
    "            drop_last=False,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.RANZCR_test,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=Config.num_workers,\n",
    "            drop_last=False,\n",
    "            shuffle=False,\n",
    "            pin_memory=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# x = RANZCRDataModule(\\n#     train_df=train_df,\\n#     test_df=test_df,\\n#     train_img_dir=train_img_dir,\\n#     test_img_dir=test_img_dir,\\n#     fold=0,\\n# )\\n# x.setup()\\n# x.train_dataloader()\";\n",
       "                var nbb_formatted_code = \"# x = RANZCRDataModule(\\n#     train_df=train_df,\\n#     test_df=test_df,\\n#     train_img_dir=train_img_dir,\\n#     test_img_dir=test_img_dir,\\n#     fold=0,\\n# )\\n# x.setup()\\n# x.train_dataloader()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x = RANZCRDataModule(\n",
    "#     train_df=train_df,\n",
    "#     test_df=test_df,\n",
    "#     train_img_dir=train_img_dir,\n",
    "#     test_img_dir=test_img_dir,\n",
    "#     fold=0,\n",
    "# )\n",
    "# x.setup()\n",
    "# x.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# F.binary_cross_en\";\n",
       "                var nbb_formatted_code = \"# F.binary_cross_en\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# F.binary_cross_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class RANZCRModel(pl.LightningModule):\\n    def __init__(\\n        self,\\n        model_name=Config.model_name,\\n        output_dim=Config.target_size,\\n        pretrained=True,\\n    ):\\n        super().__init__()\\n        self.backbone = timm.create_model(model_name, pretrained=pretrained)\\n\\n        n_features = self.backbone.fc.in_features\\n        self.backbone.fc = nn.Identity()\\n        self.backbone.global_pool = nn.Identity()\\n        self.pooling = nn.AdaptiveAvgPool2d(1)\\n        self.fc = nn.Linear(n_features, output_dim)\\n\\n    def binary_loss(self, logits, labels):\\n        return F.binary_cross_entropy_with_logits(logits, labels)\\n\\n    def macro_auc(self, labels, pred, plot=False):\\n        if plot:\\n            fig, ax = plt.subplots(figsize=(8, 5))\\n        aucs = []\\n        for i, col in enumerate(Config.target_cols):\\n            fpr, tpr, threshold = roc_curve(labels[:, i], pred[:, i])\\n            roc_auc = auc(fpr, tpr)\\n            aucs.append(roc_auc)\\n\\n            if plot:\\n                plt.plot(fpr, tpr, label=f\\\"Field {col} (AUC = {roc_auc:.4f})\\\")\\n\\n        mean_auc = np.mean(aucs)\\n        std_auc = np.std(aucs)\\n\\n        if plot:\\n            ax.plot([0, 1], [0, 1], label=\\\"Luck\\\", linestyle=\\\"--\\\", color=\\\"r\\\")\\n            ax.plot(\\n                mean_auc, label=f\\\"Average AUC score: {mean_auc:.4f} $\\\\pm$ {std_auc:.4f}\\\"\\n            )\\n            ax.legend(loc=\\\"lower right\\\")\\n            ax.set(\\n                xlim=[-0.1, 1.1],\\n                ylim=[-0.1, 1.1],\\n                title=f\\\"Average AUC over {Config.target_size} fields\\\",\\n            )\\n            plt.show()\\n        return mean_auc\\n\\n    def forward(self, x):\\n        bs = x.size(0)\\n        features = self.backbone(x)\\n        pooled_features = self.pooling(features).view(bs, -1)\\n        output = self.fc(pooled_features)\\n        return output\\n\\n    def training_step(self, train_batch, batch_idx):\\n\\n        x, y = train_batch\\n        logits = self.forward(x)\\n        loss = self.binary_loss(logits, y).unsqueeze(0)\\n        #         self.log(\\\"train_loss\\\", loss)\\n        #         auc = self.macro_auc(logits, y)\\n        tb_log = {\\n            \\\"train_loss\\\": loss,\\n            #                   \\\"train_auc\\\": auc\\n        }\\n        return {\\n            \\\"loss\\\": loss,\\n            #                 \\\"train_auc\\\": auc,\\n            \\\"log\\\": tb_log,\\n        }\\n\\n    def validation_step(self, val_batch, batch_idx):\\n        x, y = val_batch\\n        logits = self.forward(x)\\n        loss = self.binary_loss(logits, y).unsqueeze(0)\\n        probs = torch.sigmoid(logits)\\n        #         self.log('val_loss', loss)\\n#         already call torch.no_grad() so we had not to call the detach()\\n        auc = self.macro_auc(logits.cpu().numpy(), y.cpu().numpy())\\n        tb_log = {\\\"val_loss\\\": loss, \\\"val_auc\\\": auc}\\n        return {\\\"val_loss\\\": loss, \\\"val_auc\\\": auc, \\\"log\\\": tb_log}\\n\\n    def validation_epoch_end(self, outputs):\\n        avg_loss = torch.cat([out[\\\"val_loss\\\"] for out in outputs], dim=0).mean()\\n        avg_auc = torch.cat([out[\\\"val_auc\\\"] for out in outputs], dim=0).mean()\\n        print(f\\\"EPOCH: {self.current_epoch} AUC:{auc:.4f}\\\")\\n        tensorboard_logs = {\\\"val_loss\\\": avg_loss, \\\"val_auc\\\": avg_auc}\\n        return {\\\"avg_val_loss\\\": avg_loss, \\\"val_auc\\\": avg_auc, \\\"log\\\": tensorboard_logs}\\n\\n    def test_step(self, batch, batch_idx):\\n        logits = self.forward(batch)\\n        probs = torch.sigmoid(logits)\\n        return {\\\"probs\\\": probs}\\n\\n    def test_epoch_end(self, outputs):\\n        y_hat = torch.cat([x[\\\"y_hat\\\"] for x in outputs])\\n        df_test[\\\"target\\\"] = y_hat.tolist()\\n\\n        os.makedirs(Config.output_dir, exists_ok=True)\\n        os.makedirs(Config.submission_dir, exists_ok=True)\\n        N = len(os.listdir(Config.output_dir))\\n        df_test.target.to_csv(os.path.join(Config.submission_dir, f\\\"submission{N}.csv\\\"))\\n        return {\\\"tta\\\": N}\\n\\n    def configure_optimizers(self):\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\\n        return optimizer\";\n",
       "                var nbb_formatted_code = \"class RANZCRModel(pl.LightningModule):\\n    def __init__(\\n        self,\\n        model_name=Config.model_name,\\n        output_dim=Config.target_size,\\n        pretrained=True,\\n    ):\\n        super().__init__()\\n        self.backbone = timm.create_model(model_name, pretrained=pretrained)\\n\\n        n_features = self.backbone.fc.in_features\\n        self.backbone.fc = nn.Identity()\\n        self.backbone.global_pool = nn.Identity()\\n        self.pooling = nn.AdaptiveAvgPool2d(1)\\n        self.fc = nn.Linear(n_features, output_dim)\\n\\n    def binary_loss(self, logits, labels):\\n        return F.binary_cross_entropy_with_logits(logits, labels)\\n\\n    def macro_auc(self, labels, pred, plot=False):\\n        if plot:\\n            fig, ax = plt.subplots(figsize=(8, 5))\\n        aucs = []\\n        for i, col in enumerate(Config.target_cols):\\n            fpr, tpr, threshold = roc_curve(labels[:, i], pred[:, i])\\n            roc_auc = auc(fpr, tpr)\\n            aucs.append(roc_auc)\\n\\n            if plot:\\n                plt.plot(fpr, tpr, label=f\\\"Field {col} (AUC = {roc_auc:.4f})\\\")\\n\\n        mean_auc = np.mean(aucs)\\n        std_auc = np.std(aucs)\\n\\n        if plot:\\n            ax.plot([0, 1], [0, 1], label=\\\"Luck\\\", linestyle=\\\"--\\\", color=\\\"r\\\")\\n            ax.plot(\\n                mean_auc, label=f\\\"Average AUC score: {mean_auc:.4f} $\\\\pm$ {std_auc:.4f}\\\"\\n            )\\n            ax.legend(loc=\\\"lower right\\\")\\n            ax.set(\\n                xlim=[-0.1, 1.1],\\n                ylim=[-0.1, 1.1],\\n                title=f\\\"Average AUC over {Config.target_size} fields\\\",\\n            )\\n            plt.show()\\n        return mean_auc\\n\\n    def forward(self, x):\\n        bs = x.size(0)\\n        features = self.backbone(x)\\n        pooled_features = self.pooling(features).view(bs, -1)\\n        output = self.fc(pooled_features)\\n        return output\\n\\n    def training_step(self, train_batch, batch_idx):\\n\\n        x, y = train_batch\\n        logits = self.forward(x)\\n        loss = self.binary_loss(logits, y).unsqueeze(0)\\n        #         self.log(\\\"train_loss\\\", loss)\\n        #         auc = self.macro_auc(logits, y)\\n        tb_log = {\\n            \\\"train_loss\\\": loss,\\n            #                   \\\"train_auc\\\": auc\\n        }\\n        return {\\n            \\\"loss\\\": loss,\\n            #                 \\\"train_auc\\\": auc,\\n            \\\"log\\\": tb_log,\\n        }\\n\\n    def validation_step(self, val_batch, batch_idx):\\n        x, y = val_batch\\n        logits = self.forward(x)\\n        loss = self.binary_loss(logits, y).unsqueeze(0)\\n        probs = torch.sigmoid(logits)\\n        #         self.log('val_loss', loss)\\n        #         already call torch.no_grad() so we had not to call the detach()\\n        auc = self.macro_auc(logits.cpu().numpy(), y.cpu().numpy())\\n        tb_log = {\\\"val_loss\\\": loss, \\\"val_auc\\\": auc}\\n        return {\\\"val_loss\\\": loss, \\\"val_auc\\\": auc, \\\"log\\\": tb_log}\\n\\n    def validation_epoch_end(self, outputs):\\n        avg_loss = torch.cat([out[\\\"val_loss\\\"] for out in outputs], dim=0).mean()\\n        avg_auc = torch.cat([out[\\\"val_auc\\\"] for out in outputs], dim=0).mean()\\n        print(f\\\"EPOCH: {self.current_epoch} AUC:{auc:.4f}\\\")\\n        tensorboard_logs = {\\\"val_loss\\\": avg_loss, \\\"val_auc\\\": avg_auc}\\n        return {\\\"avg_val_loss\\\": avg_loss, \\\"val_auc\\\": avg_auc, \\\"log\\\": tensorboard_logs}\\n\\n    def test_step(self, batch, batch_idx):\\n        logits = self.forward(batch)\\n        probs = torch.sigmoid(logits)\\n        return {\\\"probs\\\": probs}\\n\\n    def test_epoch_end(self, outputs):\\n        y_hat = torch.cat([x[\\\"y_hat\\\"] for x in outputs])\\n        df_test[\\\"target\\\"] = y_hat.tolist()\\n\\n        os.makedirs(Config.output_dir, exists_ok=True)\\n        os.makedirs(Config.submission_dir, exists_ok=True)\\n        N = len(os.listdir(Config.output_dir))\\n        df_test.target.to_csv(os.path.join(Config.submission_dir, f\\\"submission{N}.csv\\\"))\\n        return {\\\"tta\\\": N}\\n\\n    def configure_optimizers(self):\\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\\n        return optimizer\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class RANZCRModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name=Config.model_name,\n",
    "        output_dim=Config.target_size,\n",
    "        pretrained=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        n_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.backbone.global_pool = nn.Identity()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(n_features, output_dim)\n",
    "\n",
    "    def binary_loss(self, logits, labels):\n",
    "        return F.binary_cross_entropy_with_logits(logits, labels)\n",
    "\n",
    "    def macro_auc(self, labels, pred):\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        aucs = []\n",
    "        for i, col in enumerate(Config.target_cols):\n",
    "            fpr, tpr, threshold = roc_curve(labels[:, i], pred[:, i])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            aucs.append(roc_auc)\n",
    "\n",
    "            plt.plot(fpr, tpr, label=f\"Field {col} (AUC = {roc_auc:.4f})\")\n",
    "\n",
    "        mean_auc = np.mean(aucs)\n",
    "        std_auc = np.std(aucs)\n",
    "\n",
    "        ax.plot([0, 1], [0, 1], label=\"Luck\", linestyle=\"--\", color=\"r\")\n",
    "        ax.plot(\n",
    "            mean_auc, label=f\"Average AUC score: {mean_auc:.4f} $\\pm$ {std_auc:.4f}\"\n",
    "        )\n",
    "        ax.legend(loc=\"lower right\")\n",
    "        ax.set(\n",
    "            xlim=[-0.1, 1.1],\n",
    "            ylim=[-0.1, 1.1],\n",
    "            title=f\"Average AUC over {Config.target_size} fields\",\n",
    "        )\n",
    "        plt.show()\n",
    "        return mean_auc\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        features = self.backbone(x)\n",
    "        pooled_features = self.pooling(features).view(bs, -1)\n",
    "        output = self.fc(pooled_features)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "\n",
    "        x, y = train_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.binary_loss(logits, y).unsqueeze(0)\n",
    "        #         self.log(\"train_loss\", loss)\n",
    "        #         auc = self.macro_auc(logits, y)\n",
    "        tb_log = {\n",
    "            \"train_loss\": loss,\n",
    "            #                   \"train_auc\": auc\n",
    "        }\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            #                 \"train_auc\": auc,\n",
    "            \"log\": tb_log,\n",
    "        }\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.binary_loss(logits, y).unsqueeze(0)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        #         self.log('val_loss', loss)\n",
    "        #         already call torch.no_grad() so we had not to call the detach()\n",
    "        auc = self.macro_auc(logits.cpu().numpy(), y.cpu().numpy())\n",
    "        tb_log = {\"val_loss\": loss, \"val_auc\": auc}\n",
    "        return {\"val_loss\": loss, \"val_auc\": auc, \"log\": tb_log}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.cat([out[\"val_loss\"] for out in outputs], dim=0).mean()\n",
    "        avg_auc = torch.cat([out[\"val_auc\"] for out in outputs], dim=0).mean()\n",
    "        print(f\"EPOCH: {self.current_epoch} AUC:{auc:.4f}\")\n",
    "        tensorboard_logs = {\"val_loss\": avg_loss, \"val_auc\": avg_auc}\n",
    "        return {\"avg_val_loss\": avg_loss, \"val_auc\": avg_auc, \"log\": tensorboard_logs}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        logits = self.forward(batch)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        return {\"probs\": probs}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        y_hat = torch.cat([x[\"y_hat\"] for x in outputs])\n",
    "        df_test[\"target\"] = y_hat.tolist()\n",
    "\n",
    "        os.makedirs(Config.output_dir, exists_ok=True)\n",
    "        os.makedirs(Config.submission_dir, exists_ok=True)\n",
    "        N = len(os.listdir(Config.output_dir))\n",
    "        df_test.target.to_csv(os.path.join(Config.submission_dir, f\"submission{N}.csv\"))\n",
    "        return {\"tta\": N}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# x = RANZCRModel()\";\n",
       "                var nbb_formatted_code = \"# x = RANZCRModel()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x = RANZCRModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "Using native 16bit precision.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"checkpoint_callback = pl.callbacks.ModelCheckpoint(\\n    \\\"{epoch:02d}_{val_auc:.4f}\\\",\\n    monitor=\\\"val_auc\\\",\\n    mode=\\\"max\\\",\\n    #     save_top_k=1,\\n)\\ntrainer = pl.Trainer(\\n    gpus=1,\\n    precision=16,\\n    max_epochs=30,\\n    num_sanity_val_steps=1 if Config.debug else 0,\\n    checkpoint_callback=checkpoint_callback,\\n    #     val_check_interval=0.25, # check validation 4 times per epoch\\n)\";\n",
       "                var nbb_formatted_code = \"checkpoint_callback = pl.callbacks.ModelCheckpoint(\\n    \\\"{epoch:02d}_{val_auc:.4f}\\\",\\n    monitor=\\\"val_auc\\\",\\n    mode=\\\"max\\\",\\n    #     save_top_k=1,\\n)\\ntrainer = pl.Trainer(\\n    gpus=1,\\n    precision=16,\\n    max_epochs=30,\\n    num_sanity_val_steps=1 if Config.debug else 0,\\n    checkpoint_callback=checkpoint_callback,\\n    #     val_check_interval=0.25, # check validation 4 times per epoch\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    \"{epoch:02d}_{val_auc:.4f}\",\n",
    "    monitor=\"val_auc\",\n",
    "    mode=\"max\",\n",
    "    #     save_top_k=1,\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    precision=16,\n",
    "    max_epochs=30,\n",
    "    num_sanity_val_steps=1 if Config.debug else 0,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    #     val_check_interval=0.25, # check validation 4 times per epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type              | Params\n",
      "-----------------------------------------------\n",
      "0 | backbone | ResNet            | 62 M  \n",
      "1 | pooling  | AdaptiveAvgPool2d | 0     \n",
      "2 | fc       | Linear            | 22 K  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d3eb523db54c70b77df0799f60bed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonard/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d58c88ac304d6f942b8b45d19f4b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "continuous format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ab84b102ff84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_fit_start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# train or test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_or_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtrain_or_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m                 \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0mshould_check_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_check_val_fx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_check_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# -----------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(self, test_mode, max_batches)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0;31m# lightning module methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mevaluation_step\u001b[0;34m(self, test_mode, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# track batch size for weighted average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp_backend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mAMPType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNATIVE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__validation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__validation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36m__validation_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d637ce6463d7>\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, val_batch, batch_idx)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m#         self.log('val_loss', loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m#         already call torch.no_grad() so we had not to call the detach()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmacro_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mtb_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val_auc\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val_auc\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"log\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtb_log\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d637ce6463d7>\u001b[0m in \u001b[0;36mmacro_auc\u001b[0;34m(self, labels, pred, plot)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0maucs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0maucs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    620\u001b[0m     \"\"\"\n\u001b[1;32m    621\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 622\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    394\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    395\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: continuous format is not supported"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"model = RANZCRModel()\\ndata_module = RANZCRDataModule(\\n    train_df=train_df,\\n    test_df=test_df,\\n    train_img_dir=train_img_dir,\\n    test_img_dir=test_img_dir,\\n    fold=0,\\n)\\ntrainer.fit(model, data_module)\";\n",
       "                var nbb_formatted_code = \"model = RANZCRModel()\\ndata_module = RANZCRDataModule(\\n    train_df=train_df,\\n    test_df=test_df,\\n    train_img_dir=train_img_dir,\\n    test_img_dir=test_img_dir,\\n    fold=0,\\n)\\ntrainer.fit(model, data_module)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = RANZCRModel()\n",
    "data_module = RANZCRDataModule(\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    train_img_dir=train_img_dir,\n",
    "    test_img_dir=test_img_dir,\n",
    "    fold=0,\n",
    ")\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
